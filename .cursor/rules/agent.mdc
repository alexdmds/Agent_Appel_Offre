---
description: 
globs: 
alwaysApply: true
---
Tu dÃ©veloppes un agent autonome en Python Ã  lâ€™aide de LangChain, dans une approche ReAct.

ğŸ¯ Objectif de lâ€™agent :
Analyser un nouveau dossier dâ€™appel dâ€™offre (AO) fourni au format brut (PDF, DOC, DOCX, XLS, XLSXâ€¦) et produire :
1. Un rÃ©sumÃ© des besoins / contraintes / dÃ©lais / critÃ¨res de notation.
2. Une recommandation Go / NoGo (en fonction du contenu et des AO passÃ©s).
3. Un dÃ©but de plan de rÃ©ponse (ou draft de rÃ©ponse structurÃ©e).
4. Un rÃ©sumÃ© clair pour un responsable.

ğŸ§  Outils Ã  disposition :
Lâ€™agent dispose de deux outils externes :
1. `query_rag(question: str)` â†’ permet de poser une question libre et dâ€™obtenir les extraits les plus pertinents des anciens AO (Go/NoGo) via un moteur RAG.
2. `read_documents_from_folder(folder_path: str)` â†’ permet de lire lâ€™ensemble des documents dâ€™un dossier AO (PDF, DOC, DOCX, XLS, XLSX) et de retourner leur contenu textuel brut. Lâ€™agent peut ensuite explorer, rÃ©sumer ou structurer ce contenu.

âš™ï¸ Fonctionnement :
- Lâ€™agent utilise le modÃ¨le `ChatMistralAI` via LangChain.
- Il doit rÃ©flÃ©chir Ã©tape par Ã©tape (*ReAct*) et utiliser les outils de maniÃ¨re autonome et justifiÃ©e.
- Il peut mÃ©moriser les rÃ©sultats intermÃ©diaires dans une mÃ©moire de travail.
- Il doit toujours produire une rÃ©ponse structurÃ©e et exploitable (Markdown si utile).

ğŸ§­ Aide au dÃ©veloppement :
- Si besoin dâ€™exemples ou de documentation sur LangChain ou `ChatMistralAI`, utilise le serveur MCP `context7` pour faire des recherches Ã  jour.

Objectif : coder un POC simple, autonome, modulaire (moins de 500 lignes si possible), exÃ©cutable localement en Python, sans dÃ©pendances complexes ni cloud externe.